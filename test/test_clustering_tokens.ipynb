{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "from src.utils import read_audio, find_files\n",
    "from src.encoder import Wav2VecBertEncoder, HubertEncoder\n",
    "from src.configs import Wav2VecBertConfig, HubertEncoderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_path = '../data/kmeans/kmeans_faiss_centroids.pkl'\n",
    "# kmeans_path = Wav2VecBertConfig.quantizer_path\n",
    "wave2vec2_kmeans = joblib.load(kmeans_path)\n",
    "\n",
    "kmeans_path = HubertEncoderConfig.quantizer_path\n",
    "hubert_kmeans = joblib.load(kmeans_path)\n",
    "\n",
    "wav2vecbert_encoder = Wav2VecBertEncoder(\n",
    "    config=Wav2VecBertConfig(), device='cuda'\n",
    ")\n",
    "\n",
    "hubert_encoder = HubertEncoder(quantize=False, device='cuda')\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(HubertEncoderConfig.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(embeddings, centroids):\n",
    "    # embeddings: B, T, D\n",
    "    # centroids: K, D\n",
    "    # return: B, T, K\n",
    "    distances = torch.cdist(embeddings, centroids)\n",
    "    return torch.min(distances, dim=-1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check the distance of any random embedding from the nearest centroid\n",
    "2. Check the distance of a legit audio from the nearest centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_emb = np.random.rand(1, 160_000) # 10 second random audio\n",
    "print(rand_emb.shape)\n",
    "\n",
    "audiopath = '../data/test-clean/LibriSpeech/test-clean/1089/134686/1089-134686-0000.flac'\n",
    "# audiopath = '/home/romit/.cache/huggingface/datasets/downloads/extracted/81c46ac239ac4614e07a0960bb4b7f62966b99a2c540db203593c975c49d4248/xs_chunks_0000/YOU0000000761_S0000321.wav'\n",
    "audio = read_audio(audiopath, 16_000)\n",
    "audio = audio[0, :160_000]\n",
    "\n",
    "print(audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    proc = processor(rand_emb, return_tensors=\"pt\", return_attention_mask=True, sampling_rate=16_000)\n",
    "    proc_ip, proc_am = proc.input_values.to('cuda'), proc.attention_mask.to('cuda')\n",
    "    print(proc_ip.shape, proc_am.shape)\n",
    "    rand_out = hubert_encoder(proc_ip, proc_am)\n",
    "    rand_out = rand_out.to('cpu')\n",
    "    \n",
    "    proc = processor(audio, return_tensors=\"pt\", return_attention_mask=True, sampling_rate=16_000)\n",
    "    proc_ip, proc_am = proc.input_values.to('cuda'), proc.attention_mask.to('cuda')\n",
    "    print(proc_ip.shape, proc_am.shape)\n",
    "    audio_out = hubert_encoder(proc_ip, proc_am)\n",
    "    audio_out = audio_out.to('cpu')\n",
    "\n",
    "    # rand_out = wav2vecbert_encoder(rand_emb, [])\n",
    "    # rand_out = rand_out.to('cpu')\n",
    "    # print(rand_out.shape)\n",
    "\n",
    "    # audio_out = wav2vecbert_encoder(audio, [])\n",
    "    # audio_out = audio_out.to('cpu')\n",
    "    # print(audio_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio_out[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rand_out[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1 = get_dist(rand_out, torch.from_numpy(hubert_kmeans.cluster_centers_))\n",
    "# d2 = get_dist(audio_out, torch.from_numpy(hubert_kmeans.cluster_centers_))\n",
    "\n",
    "d1 = get_dist(rand_out, torch.from_numpy(wave2vec2_kmeans))#.cluster_centers_))\n",
    "d2 = get_dist(audio_out, torch.from_numpy(wave2vec2_kmeans))#.cluster_centers_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hubert_dist(\n",
    "    encoder,\n",
    "    processor,\n",
    "    centroids,\n",
    "    audio_path\n",
    "):\n",
    "\n",
    "    # Audio\n",
    "    audio = read_audio(audio_path, 16_000)\n",
    "    audio = audio[0, :160_000]\n",
    "    proc = processor(audio, return_tensors=\"pt\", return_attention_mask=True, sampling_rate=16_000)\n",
    "    proc_ip, proc_am = proc.input_values.to('cuda'), proc.attention_mask.to('cuda')\n",
    "    audio_out = encoder(proc_ip, proc_am)\n",
    "    audio_out = audio_out.to('cpu')\n",
    "    d1 = get_dist(audio_out, centroids)\n",
    "\n",
    "    # Random embedding\n",
    "    rand_emb = np.random.rand(1, 160_000)  # 10 second random audio\n",
    "    proc = processor(rand_emb, return_tensors=\"pt\", return_attention_mask=True, sampling_rate=16_000)\n",
    "    proc_ip, proc_am = proc.input_values.to('cuda'), proc.attention_mask.to('cuda')\n",
    "    rand_out = encoder(proc_ip, proc_am)\n",
    "    rand_out = rand_out.to('cpu')\n",
    "    d2 = get_dist(rand_out, centroids)\n",
    "\n",
    "    return d1, d2\n",
    "\n",
    "\n",
    "def wav2vec2_dist(\n",
    "    encoder,\n",
    "    centroids,\n",
    "    audio_path\n",
    "):\n",
    "\n",
    "    # Audio\n",
    "    audio = read_audio(audio_path, 16_000)\n",
    "    audio = audio[0, :160_000]\n",
    "    audio_out = encoder(audio, [])\n",
    "    audio_out = audio_out.to('cpu')\n",
    "    d1 = get_dist(audio_out, centroids)\n",
    "\n",
    "    # Random embedding\n",
    "    rand_emb = np.random.rand(1, 160_000)  # 10 second random audio\n",
    "    rand_out = encoder(rand_emb, [])\n",
    "    rand_out = rand_out.to('cpu')\n",
    "    d2 = get_dist(rand_out, centroids)\n",
    "\n",
    "    return d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = find_files('../data/test-clean/LibriSpeech/test-clean/', ('.flac'))\n",
    "print(len(audio_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rand_pool = []\n",
    "audio_pool = []\n",
    "\n",
    "for f in tqdm(audio_files):\n",
    "    audio_dist, rand_dist = hubert_dist(hubert_encoder, processor, torch.from_numpy(hubert_kmeans.cluster_centers_), f)\n",
    "    # audio_dist, rand_dist = wav2vec2_dist(wav2vecbert_encoder, torch.from_numpy(wave2vec2_kmeans), f)\n",
    "\n",
    "    # Add to a pool of distances\n",
    "    audio_pool.extend(audio_dist)\n",
    "    rand_pool.extend(rand_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.concatenate(audio_pool)\n",
    "r = np.concatenate(rand_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(a, alpha=1, label='Audio')\n",
    "plt.hist(r, alpha=0.75, label='Random')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Distance of a token from centroid')\n",
    "# plt.savefig('wav2vec2_clusterdiff.png')\n",
    "plt.savefig('hubert_clusterdiff.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
