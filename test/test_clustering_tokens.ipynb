{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "from src.utils import read_audio\n",
    "from src.encoder import Wav2VecBertEncoder, HubertEncoder\n",
    "from src.configs import Wav2VecBertConfig, HubertEncoderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_path = '../data/kmeans_faiss_centroids.pkl'\n",
    "# kmeans_path = Wav2VecBertConfig.quantizer_path\n",
    "wave2vec2_kmeans = joblib.load(kmeans_path)\n",
    "\n",
    "kmeans_path = HubertEncoderConfig.quantizer_path\n",
    "hubert_kmeans = joblib.load(kmeans_path)\n",
    "\n",
    "wav2vecbert_encoder = Wav2VecBertEncoder(\n",
    "    config=Wav2VecBertConfig(),\n",
    ")\n",
    "\n",
    "hubert_encoder = HubertEncoder(quantize=False)\n",
    "\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(HubertEncoderConfig.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(embeddings, centroids):\n",
    "    # embeddings: B, T, D\n",
    "    # centroids: K, D\n",
    "    # return: B, T, K\n",
    "    distances = torch.cdist(embeddings, centroids)\n",
    "    return torch.min(distances, dim=-1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check the distance of any random embedding from the nearest centroid\n",
    "2. Check the distance of a legit audio from the nearest centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_emb = np.random.rand(1, 160_000) # 10 second random audio\n",
    "print(rand_emb.shape)\n",
    "\n",
    "audiopath = '../data/test-clean/LibriSpeech/test-clean/1089/134686/1089-134686-0000.flac'\n",
    "# audiopath = '/home/romit/.cache/huggingface/datasets/downloads/extracted/81c46ac239ac4614e07a0960bb4b7f62966b99a2c540db203593c975c49d4248/xs_chunks_0000/YOU0000000761_S0000321.wav'\n",
    "audio = read_audio(audiopath, 16_000)\n",
    "audio = audio[0, :160_000]\n",
    "\n",
    "print(audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc = processor(rand_emb, return_tensors=\"pt\", return_attention_mask=True, sampling_rate=16_000)\n",
    "# proc_ip, proc_am = proc.input_values, proc.attention_mask\n",
    "# rand_out = hubert_encoder(proc_ip, proc_am)\n",
    "\n",
    "# proc = processor(audio, return_tensors=\"pt\", return_attention_mask=True, sampling_rate=16_000)\n",
    "# proc_ip, proc_am = proc.input_values, proc.attention_mask\n",
    "# audio_out = hubert_encoder(proc_ip, proc_am)\n",
    "\n",
    "rand_out = wav2vecbert_encoder(rand_emb, [])\n",
    "print(rand_out.shape)\n",
    "\n",
    "audio_out = wav2vecbert_encoder(audio, [])\n",
    "print(audio_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio_out[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rand_out[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1 = get_dist(rand_out, torch.from_numpy(hubert_kmeans.cluster_centers_))\n",
    "# d2 = get_dist(audio_out, torch.from_numpy(hubert_kmeans.cluster_centers_))\n",
    "\n",
    "d1 = get_dist(rand_out, torch.from_numpy(wave2vec2_kmeans))#.cluster_centers_))\n",
    "d2 = get_dist(audio_out, torch.from_numpy(wave2vec2_kmeans))#.cluster_centers_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d1, d1.shape)\n",
    "print(d2, d2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1[0].mean(), d2[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(d1[0].detach().numpy())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(d2[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encodec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
