{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import Wav2Vec2FeatureExtractor, AutoFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "from torch.cuda import empty_cache\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils import read_audio, find_files\n",
    "from src.encoder import Wav2VecBertEncoder, HubertEncoder, wav2vec_processor\n",
    "from src.configs import Wav2VecBertConfig, HubertEncoderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_path = '../data/kmeans/kmeans__L-1_C1024_ckpt150.pkl'\n",
    "wave2vec2_kmeans = joblib.load(kmeans_path)\n",
    "wav2vecbert_processor = AutoFeatureExtractor.from_pretrained(Wav2VecBertConfig.model_id)\n",
    "wav2vecbert_encoder = Wav2VecBertEncoder(\n",
    "    config=Wav2VecBertConfig(), device='cuda'\n",
    ")\n",
    "\n",
    "# kmeans_path = HubertEncoderConfig.quantizer_path\n",
    "# hubert_kmeans = joblib.load(kmeans_path)\n",
    "# hubert_encoder = HubertEncoder(quantize=False, device='cuda')\n",
    "# processor = Wav2Vec2FeatureExtractor.from_pretrained(HubertEncoderConfig.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(embeddings, centroids):\n",
    "    # embeddings: B, T, D\n",
    "    # centroids: K, D\n",
    "    # return: B, T, K\n",
    "\n",
    "    distances = torch.cdist(embeddings, centroids)\n",
    "    return torch.min(distances, dim=-1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check the distance of any random embedding from the nearest centroid\n",
    "2. Check the distance of a legit audio from the nearest centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_emb = np.random.rand(1, 160_000) # 10 second random audio\n",
    "print(rand_emb.shape)\n",
    "\n",
    "audiopath = '../data/test-clean/LibriSpeech/test-clean/1089/134686/1089-134686-0000.flac'\n",
    "# audiopath = '/home/romit/.cache/huggingface/datasets/downloads/extracted/81c46ac239ac4614e07a0960bb4b7f62966b99a2c540db203593c975c49d4248/xs_chunks_0000/YOU0000000761_S0000321.wav'\n",
    "audio = read_audio(audiopath, 16_000)\n",
    "audio = audio[0, :160_000]\n",
    "\n",
    "print(audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # proc = processor(rand_emb, return_tensors=\"pt\", return_attention_mask=True, sampling_rate=16_000)\n",
    "    # proc_ip, proc_am = proc.input_values.to('cuda'), proc.attention_mask.to('cuda')\n",
    "    # print(proc_ip.shape, proc_am.shape)\n",
    "    # rand_out = hubert_encoder(proc_ip, proc_am)\n",
    "    # rand_out = rand_out.to('cpu')\n",
    "    \n",
    "    # proc = processor(audio, return_tensors=\"pt\", return_attention_mask=True, sampling_rate=16_000)\n",
    "    # proc_ip, proc_am = proc.input_values.to('cuda'), proc.attention_mask.to('cuda')\n",
    "    # print(proc_ip.shape, proc_am.shape)\n",
    "    # audio_out = hubert_encoder(proc_ip, proc_am)\n",
    "    # audio_out = audio_out.to('cpu')\n",
    "\n",
    "    ii, am = wav2vec_processor(rand_emb, wav2vecbert_processor)\n",
    "    rand_out = wav2vecbert_encoder(ii.to('cuda'), am.to('cuda'))\n",
    "    rand_out = rand_out.to('cpu')\n",
    "    print(rand_out.shape)\n",
    "\n",
    "    ii, am = wav2vec_processor(audio, wav2vecbert_processor)\n",
    "    audio_out = wav2vecbert_encoder(ii.to('cuda'), am.to('cuda'))\n",
    "    audio_out = audio_out.to('cpu')\n",
    "    print(audio_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1 = get_dist(rand_out, torch.from_numpy(hubert_kmeans.cluster_centers_))\n",
    "# d2 = get_dist(audio_out, torch.from_numpy(hubert_kmeans.cluster_centers_))\n",
    "\n",
    "d1 = get_dist(rand_out, torch.from_numpy(wave2vec2_kmeans.cluster_centers_))\n",
    "d2 = get_dist(audio_out, torch.from_numpy(wave2vec2_kmeans.cluster_centers_))\n",
    "\n",
    "d1.mean(), d2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hubert_dist(\n",
    "    encoder,\n",
    "    processor,\n",
    "    centroids,\n",
    "    audio_path\n",
    "):\n",
    "\n",
    "    # Audio\n",
    "    audio = read_audio(audio_path, 16_000)\n",
    "    audio = audio[0, :160_000]\n",
    "    proc = processor(audio, return_tensors=\"pt\", return_attention_mask=True, sampling_rate=16_000)\n",
    "    proc_ip, proc_am = proc.input_values.to('cuda'), proc.attention_mask.to('cuda')\n",
    "    audio_out = encoder(proc_ip, proc_am)\n",
    "    audio_out = audio_out.to('cpu')\n",
    "    d1 = get_dist(audio_out, centroids)\n",
    "\n",
    "    # Random embedding\n",
    "    rand_emb = np.random.rand(1, 160_000)  # 10 second random audio\n",
    "    proc = processor(rand_emb, return_tensors=\"pt\", return_attention_mask=True, sampling_rate=16_000)\n",
    "    proc_ip, proc_am = proc.input_values.to('cuda'), proc.attention_mask.to('cuda')\n",
    "    rand_out = encoder(proc_ip, proc_am)\n",
    "    rand_out = rand_out.to('cpu')\n",
    "    d2 = get_dist(rand_out, centroids)\n",
    "\n",
    "    return d1, d2\n",
    "\n",
    "\n",
    "def wav2vec2_dist(\n",
    "    encoder,\n",
    "    centroids,\n",
    "    audio_path\n",
    "):\n",
    "\n",
    "    # Audio\n",
    "    audio = read_audio(audio_path, 16_000)\n",
    "    audio = audio[0, :160_000]\n",
    "    ii, am = wav2vec_processor(audio, wav2vecbert_processor)\n",
    "    audio_out = encoder(ii.to('cuda'), am.to('cuda'))[layer]\n",
    "    audio_out = audio_out.detach().to('cpu')\n",
    "    d1 = get_dist(audio_out, centroids)\n",
    "\n",
    "    # Random embedding\n",
    "    # rand_emb = np.random.rand(1, 160_000)  # 10 second random audio\n",
    "    # ii, am = wav2vec_processor(rand_emb, wav2vecbert_processor)\n",
    "    # rand_out = encoder(ii.to('cuda'), am.to('cuda'))\n",
    "    # rand_out = rand_out.detach().to('cpu')\n",
    "    # rand_emb = torch.rand_like(audio_out)\n",
    "    # d2 = get_dist(rand_emb, centroids)\n",
    "\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = find_files('../data/test-clean/LibriSpeech/test-clean/', ('.flac'))\n",
    "print(len(audio_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for a in tqdm(audio_files[:100], total=100):\n",
    "    audio = read_audio(a, 16_000)\n",
    "    audio = audio[0, :160_000]\n",
    "    ii, am = wav2vec_processor(audio, wav2vecbert_processor)\n",
    "\n",
    "    ii = F.pad(ii, (0, 0, 500-ii.shape[1], 0, 0, 0), value=0)\n",
    "    am = F.pad(am, (500-am.shape[1], 0), value=0)\n",
    "\n",
    "    out = wav2vecbert_encoder(ii.to('cuda'), am.to('cuda'))[layer]\n",
    "    embeddings.append(out.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.from_numpy(np.array(embeddings)).reshape(500*34, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = torch.linalg.vector_norm(temp, dim=(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(norms)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vectors = []\n",
    "for norm in tqdm(norms[:10000]):\n",
    "    random_vec = torch.randn(1, 1024)\n",
    "    random_vec = random_vec / torch.norm(random_vec)\n",
    "    random_vec = random_vec * norm\n",
    "    random_vectors.append(random_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_embeddings = torch.from_numpy(np.array(random_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(torch.linalg.vector_norm(random_embeddings, dim=(-1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rand_pool = []\n",
    "audio_pool = []\n",
    "\n",
    "for f in tqdm(audio_files[:500]):\n",
    "    # audio_dist, rand_dist = hubert_dist(hubert_encoder, processor, torch.from_numpy(hubert_kmeans.cluster_centers_), f)\n",
    "    audio_dist = wav2vec2_dist(wav2vecbert_encoder, torch.from_numpy(wave2vec2_kmeans.cluster_centers_), f)\n",
    "\n",
    "    # Add to a pool of distances\n",
    "    audio_pool.extend(audio_dist)\n",
    "\n",
    "    empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_pool = []\n",
    "for re in tqdm(random_embeddings):\n",
    "    d = get_dist(re, torch.from_numpy(wave2vec2_kmeans.cluster_centers_))\n",
    "    rand_pool.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.concatenate(audio_pool)\n",
    "r = np.concatenate(rand_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.random.choice(a, 10000), alpha=1, label='Audio')\n",
    "plt.hist(r, alpha=0.75, label='Random')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Distance of a token from centroid')\n",
    "plt.savefig(f'wav2vec2_clusterdiff_xs_{layer}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(embeddings[0][0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
