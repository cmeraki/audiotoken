{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40094ec2-675b-4948-b46d-b0a1cb0e2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "# Only 1 import required from AudioToken\n",
    "from audiotoken import AudioToken, Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67259d89-421b-48ca-9e66-c9e2f7a85e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_path = '..'\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a8283-6a08-4bbe-ba62-428b77af9394",
   "metadata": {},
   "source": [
    "## Acoustic tokenizer\n",
    "\n",
    "We can use an acoustic tokenizer to encode audio and then use its decoder to generate the same audio back. This works as a lossy compression and preserves audio characteristics like speech style, loudness, pitch, etc.\n",
    "\n",
    "Acoustic tokens are very tough to model directly using sequence to sequence models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a80077-2a2d-4bb8-bc3e-7176f2950f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_tokenizer = AudioToken(tokenizer=Tokenizers.acoustic, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed1fcb-3604-4357-a93e-6e3c35fdd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_audio = acoustic_tokenizer.encode(Path(audio_path).expanduser())\n",
    "decoded_audio = acoustic_tokenizer.decode(encoded_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ae525-718b-4622-8f0e-ddf89641981e",
   "metadata": {},
   "source": [
    "Compare the original audio with the reconstructed audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30deceaf-c946-46c5-be1c-ba8f3c8996c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original audio')\n",
    "display(Audio(Path(audio_path).expanduser()))\n",
    "print('Reconstructed audio')\n",
    "display(Audio(decoded_audio, rate=24_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28054583-f9ea-42da-b0e9-5abb0460cfc1",
   "metadata": {},
   "source": [
    "## Semantic Tokenizer\n",
    "\n",
    "We can use a semantic tokenizer to encode audio and extract semantic meaning from it. Although this tokenization loses many of the acoustic characteristics that an acoustic tokenizer preserves, semantic tokens are useful for modeling long-term audio content.\n",
    "To reconstruct the original audio from semantic tokens, we follow two steps:\n",
    "\n",
    "1. We use an autoregressive sequence-to-sequence model to translate semantic tokens into acoustic tokens (with 2 codebooks).\n",
    "2. We use a non-autoregressive model to generate acoustic tokens for 6 additional codebooks.\n",
    "\n",
    "Once we have acoustic tokens for all 8 codebooks, we can use the acoustic tokenizer to decode these tokens back into audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0098a8-caeb-42d3-b4e7-67f8361b1e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_tokenizer = AudioToken(tokenizer=Tokenizers.semantic_m, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74fbe1-2e4c-4f7a-9fdd-cab08e01a6d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_semantic_tokens = semantic_tokenizer.encode(Path(audio_path).expanduser(), chunk_size=30)\n",
    "audio_acoustic_tokens = semantic_tokenizer.decode(audio_semantic_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30bbe3-c3be-46b6-acb1-10d2c6e668ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_semantic_tokens.shape, audio_acoustic_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6409502-0f39-4afc-9dcf-2d7e4628f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_audio_semantic = acoustic_tokenizer.decode(audio_acoustic_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f5f1c-c710-4769-b6a5-705bb5d45782",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original audio')\n",
    "display(Audio(Path(audio_path).expanduser()))\n",
    "print('Reconstructed audio')\n",
    "display(Audio(reconstructed_audio_semantic, rate=24_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce39a52-a576-4a89-a170-72142438943d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
